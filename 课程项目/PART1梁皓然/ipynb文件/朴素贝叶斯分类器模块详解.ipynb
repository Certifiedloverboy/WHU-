{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608f0fa1",
   "metadata": {},
   "source": [
    "# <center>朴素贝叶斯分类器模块详解</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e60d1",
   "metadata": {},
   "source": [
    "## 一、申明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02585a8d",
   "metadata": {},
   "source": [
    "本程序使用的贝叶斯模块是GitHub上由**steve.wang**创建的，链接请点[**这里**](https://github.com/stevewang0/MLInAction)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f593ff",
   "metadata": {},
   "source": [
    "## 二、解读"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e821c8e",
   "metadata": {},
   "source": [
    "P.S:括号中斜体为我自己的标注，其余皆为模块文件中的原文"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b41a1",
   "metadata": {},
   "source": [
    "* 引用标准库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1079a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:08:13.632998Z",
     "start_time": "2021-11-12T06:08:13.622996Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64874bb",
   "metadata": {},
   "source": [
    "* dataSet：文档样本集\n",
    "\n",
    "* 创建dataSet包含的所有文档中出现的不重复词的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253ef474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:08:46.345984Z",
     "start_time": "2021-11-12T06:08:46.335477Z"
    }
   },
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([]) #创建一个空集合变量\n",
    "    for document in dataSet:\n",
    "        #set(document)获得document中所有不重复的词\n",
    "        #vocabSet | set(document)求集合的并集，返回不重复的词集合\n",
    "        #在数学符号表示上，按位或操作与集合求并操作使用相同记号\"|\"\n",
    "        vocabSet = vocabSet | set(document)\n",
    "    return list(vocabSet) #将集合转换为列表并返回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f535450",
   "metadata": {},
   "source": [
    "* vocabList: 词汇表\n",
    "\n",
    "* inputSet: 测试样本文档\n",
    "\n",
    "* 获取测试样本中单词在词汇表中是否出现的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd06831b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:09:26.163371Z",
     "start_time": "2021-11-12T06:09:26.150369Z"
    }
   },
   "outputs": [],
   "source": [
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    #定义一个列表变量，其长度与vocabList一样，其内容初始化为0\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList: #判断测试文档中的单词是否存在于词汇表\n",
    "            #index() 函数用于从列表中找出某个值第一个匹配项的索引位置\n",
    "            #寻找当前单词在词汇表vocabList中的位置，在列表returnVec对应位置写1，表示该单词存在于词汇表\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:\n",
    "            print (\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f6561",
   "metadata": {},
   "source": [
    "* vocabList: 词汇表\n",
    "\n",
    "* inputSet: 测试样本文档\n",
    "\n",
    "* 获取表示测试样本中单词在词汇表中出现次数的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8dcb05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:10:07.033637Z",
     "start_time": "2021-11-12T06:10:07.027636Z"
    }
   },
   "outputs": [],
   "source": [
    "def bagOfWords2Vec(vocabList, inputSet):\n",
    "    #定义一个列表变量，其长度与vocabList一样，其内容初始化为0\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList: #判断测试文档中的单词是否存在于词汇表\n",
    "            #index() 函数用于从列表中找出某个值第一个匹配项的索引位置\n",
    "            #寻找当前单词在词汇表vocabList中的位置，在列表returnVec对应位置累加1，记录该单词在词汇表中出现的次数\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "        else:\n",
    "            print (\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2548f",
   "metadata": {},
   "source": [
    "* trainMatrix: 存储每个文档样本在词汇表中各个词汇出现情况的集合，与样本数目相同\n",
    "\n",
    "* 这是一个二维数组，第一维对应各个文档样本id，第二维对应该样本中词汇在词汇表中出现情况\n",
    "\n",
    "* trainCategory: 存储每个文档样本所属类别的标签，即分类信息\n",
    "\n",
    "* 获取侮辱性和非侮辱性样本中各个词汇出现的概率，及样本集的侮辱性概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0479d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:51:10.239735Z",
     "start_time": "2021-11-12T06:51:10.225227Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainNB0(trainMatrix, trainCategory):\n",
    "    numTrainDocs = len(trainMatrix) #获取文档样本个数\n",
    "    numWords = len(trainMatrix[0]) #获取词汇表的长度\n",
    "    pAbusive = sum(trainCategory) / float(numTrainDocs) #获取所有样本的分类概率\n",
    "    p0Num = ones(numWords) #创建有numWords个元素的数组，且每个元素初始化为1\n",
    "    p1Num = ones(numWords) #创建有numWords个元素的数组，且每个元素初始化为1\n",
    "    p0Denom = 2.0 #存储所有样本中非侮辱性词汇出现次数总和\n",
    "    p1Denom = 2.0 #存储所有样本中侮辱性词汇出现次数总和    \n",
    "    for i in range(numTrainDocs): #逐个样本进行循环处理\n",
    "        if trainCategory[i] == 1: #如果当前样本的分类结果为1，即abusive，则对p1xx进行调整\n",
    "            #p1Num和trainMatrix[i]为含相同数目元素的list，此处的+是对应位置上元素的相加\n",
    "            p1Num += trainMatrix[i]\n",
    "            #sum(trainMatrix[i])求得第i个样本中所有侮辱性词汇出现的个数\n",
    "            p1Denom += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += sum(trainMatrix[i])\n",
    "    \n",
    "    p1Vect = log(p1Num / p1Denom)\n",
    "    #对list变量p0Num中每个元素都除以p0Denom，求得词汇表中每个词汇在所有非侮辱性样本中出现的概率（这是贝叶斯分类器的关键，这个值实际上就是贝叶斯公式中的**类条件概率**，得到这个类条件概率后再由**属性条件独立性假设**求联合概率，得到最终的联合概率就可以通过比大小实现分类了）\n",
    "    p0Vect = log(p0Num / p0Denom)\n",
    "    return p0Vect, p1Vect, pAbusive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28425657",
   "metadata": {},
   "source": [
    "* 利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率。\n",
    "\n",
    "* 即计算p(w0|1)p(w1|1)p(w2|1)。如果其中一个概率值为0，那么最后的乘积也为0。\n",
    "\n",
    "* 为降低这种影响，将所有词的出现数初始化为1，并将分母初始化为2。*（这种方法叫做**拉普拉斯修正**，作用是为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，在估计概率值时通常要进行“平滑”。）*\n",
    "\n",
    "* p0Num = zeros(numWords) #创建有numWords个元素的数组，且每个元素初始化为0\n",
    "\n",
    "* p1Num = zeros(numWords) #创建有numWords个元素的数组，且每个元素初始化为0\n",
    "\n",
    "* p0Denom = 0.0 #存储所有样本中非侮辱性词汇出现次数总和\n",
    "\n",
    "* p1Denom = 0.0 #存储所有样本中侮辱性词汇出现次数总和"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bba37",
   "metadata": {},
   "source": [
    "* 当计算乘积p(w0|ci)p(w1|ci)p(w2|ci)...p(wN|ci)时，由于大部分因子都非常小，所以程序会下溢出或者得到不正确的答案。\n",
    "\n",
    "* 一种解决办法是对乘积取自然对数。在代数中有ln(a*b)=ln(a)+ln(b)，于是通过求对数可以避免下溢出或者浮点数舍入导致的错误。\n",
    "\n",
    "* 同时，采用自然对数进行处理不会有任何损失。   \n",
    "\n",
    "* 对list变量p1Num中每个元素都除以p1Denom，求得词汇表中每个词汇在所有侮辱性样本中出现的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dcc5fd",
   "metadata": {},
   "source": [
    "* vec2Classify：测试样本中单词在词汇表中出现情况信息\n",
    "\n",
    "* p0Vec：非侮辱性词汇出现的概率\n",
    "\n",
    "* p1Vec: 侮辱性词汇出现的概率\n",
    "\n",
    "* pClass1: 训练样本中侮辱性样本的概率\n",
    "\n",
    "* 判断输入样本信息是否为侮辱性样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3de3f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:24:58.492834Z",
     "start_time": "2021-11-12T06:24:58.482438Z"
    }
   },
   "outputs": [],
   "source": [
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    #sum(vec2Classify * p1Vec): 求两个向量对应元素乘积之和，计算测试样本中侮辱性词汇的概率\n",
    "    p1 = sum(vec2Classify * p1Vec) + log(pClass1)\n",
    "    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)\n",
    "    if p1 > p0: #比较侮辱性概率和非侮辱性概率，p1大，则为侮辱性样本；反之，为非侮辱性样本\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0313695",
   "metadata": {},
   "source": [
    "* bigString：英文句子\n",
    "* 解析英文句子，将其中长度大于2单词抽取出来，并将其全部转换为小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d874c6a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-12T06:25:35.761013Z",
     "start_time": "2021-11-12T06:25:35.746507Z"
    }
   },
   "outputs": [],
   "source": [
    "def textParse(bigString):\n",
    "    #分隔bigString中的单词，分隔符为除单词、数字外的任意字符串\n",
    "    listOfTokens = re.split(r'\\W*', bigString)\n",
    "    #选出长度大于2的单词变为小写\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "185.937px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

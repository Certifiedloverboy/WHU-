
* 该程序运行需要的第三方库：

NLTK中的tokenize（分词）、stopwords（停止词）、stem（ 词干提取与词形还原）、wordnet（词形还原）

textblob（情感分析）、jieba（分词）、wordcloud（生成词云）、、numpy（为词云提供形状背景）

* 该程序运行需要的标准库：

re库 sys库 optparse库 PIL库 matplotlib.pyplot
